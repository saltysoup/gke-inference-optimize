
apiVersion: batch/v1
kind: Job
metadata:
  name: vllm-benchmark-235b-a22b
spec:
  template:
    metadata:
      labels:
        app: vllm-benchmark-235b-a22b
    spec:
      restartPolicy: OnFailure
      nodeSelector:
        cloud.google.com/gke-nodepool: "default-pool"
      containers:
      - name: vllm-benchmark-235b-a22b
        image: us-central1-docker.pkg.dev/gpu-launchpad-playground/gke-inference/benchmark-client:latest # modify
        env:
        - name: HUGGING_FACE_HUB_TOKEN
          valueFrom:
            secretKeyRef:
              name: hf-secret
              key: hf_api_token
        - name: MODEL
          value: "/Qwen/Qwen3-235B-A22B-Thinking-2507"
        - name: CLUSTER_IP
          value: "34.118.235.91"
        command:
          - sh
          - -c
          - "vllm bench serve --backend vllm --host $CLUSTER_IP --port 8080 --model $MODEL --dataset-name random --random-input-len 256 --random-output-len 1024 --ignore-eos --percentile-metrics ttft,tpot,itl,e2el"
        resources:
          limits:
            cpu: "8"
            memory: "16G"
          requests:
            cpu: "8"
            memory: "16G"
        ports:
          - containerPort: 8080

