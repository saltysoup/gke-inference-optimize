
apiVersion: batch/v1
kind: Job
metadata:
  name: vllm-benchmark-8b
spec:
  template:
    metadata:
      labels:
        app: vllm-benchmark-8b
    spec:
      restartPolicy: OnFailure
      nodeSelector:
        cloud.google.com/gke-nodepool: "default-pool"
      containers:
      - name: vllm-benchmark-8b
        image: us-central1-docker.pkg.dev/gpu-launchpad-playground/gke-inference/benchmark-client:latest # modify
        env:
        - name: HUGGING_FACE_HUB_TOKEN
          valueFrom:
            secretKeyRef:
              name: hf-secret
              key: hf_api_token
        - name: MODEL
          value: "Qwen/Qwen3-8B"
        - name: CLUSTER_IP
          value: "34.118.236.109" # kubectl get svc
        command:
          - sh
          - -c
          - "vllm bench serve --backend vllm --host $CLUSTER_IP --port 8080 --model $MODEL --dataset-name sonnet --dataset-path benchmarks/sonnet.txt --sonnet-input-len 2048 --sonnet-output-len 128 --sonnet-prefix-len 0 --num-prompts 1000 --ignore-eos --request-rate 8 --percentile-metrics ttft,tpot,itl,e2el"
        resources:
          limits:
            cpu: "8"
            memory: "16G"
          requests:
            cpu: "8"
            memory: "16G"
        ports:
          - containerPort: 8080

