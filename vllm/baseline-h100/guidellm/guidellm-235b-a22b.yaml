
apiVersion: batch/v1
kind: Job
metadata:
  name: guidellm-benchmark-235b-a22b
spec:
  template:
    metadata:
      labels:
        app: guidellm-benchmark-235b-a22b
    spec:
      restartPolicy: OnFailure
      nodeSelector:
        cloud.google.com/gke-nodepool: "default-pool"
      containers:
      - name: guidellm-benchmark-235b-a22b
        image: us-central1-docker.pkg.dev/gpu-launchpad-playground/gke-inference/benchmark-client:latest # modify
        env:
        - name: HUGGING_FACE_HUB_TOKEN
          valueFrom:
            secretKeyRef:
              name: hf-secret
              key: hf_api_token
        - name: MODEL
          value: "Qwen/Qwen3-235B-A22B-Thinking-2507"
        - name: CLUSTER_IP
          value: "34.118.235.91" # kubectl get svc
        command:
          - sh
          - -c
          - "guidellm benchmark --target http://$CLUSTER_IP:8080 --model $MODEL --data 'prompt_tokens=256,output_tokens=1024' --rate-type sweep --max-seconds 30"
        resources:
          limits:
            cpu: "8"
            memory: "16G"
          requests:
            cpu: "8"
            memory: "16G"
        ports:
          - containerPort: 8080

